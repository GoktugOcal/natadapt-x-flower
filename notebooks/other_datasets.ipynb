{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser, Namespace\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.backends.cudnn as cudnn\n",
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "from copy import deepcopy\n",
    "import shutil\n",
    "\n",
    "_NUM_CLASSES = 100\n",
    "DEVICE = torch.device(\"mps\")\n",
    "DT_FORMAT = \"%Y-%m-%d %H:%M:%S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_progress(index, length, **kwargs):\n",
    "    '''\n",
    "        display progress\n",
    "        \n",
    "        Input:\n",
    "            `index`: (int) shows the index of current progress\n",
    "            `length`: (int) total length of the progress\n",
    "            `**kwargs`: info to display (e.g. accuracy)\n",
    "    '''\n",
    "    barLength = 10 # Modify this to change the length of the progress bar\n",
    "    progress = float(index/length)\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "    block = int(round(barLength*progress))\n",
    "    text = \"\\rPercent: [{0}] {1:.2f}% ({2}/{3}) \".format( \n",
    "            \"#\"*block + \"-\"*(barLength-block), round(progress*100, 3), \\\n",
    "            index, length)\n",
    "    for key, value in kwargs.items():\n",
    "        text = text + str(key) + ': ' + str(value) + ', '\n",
    "    if len(kwargs) != 0:\n",
    "        text = text[:-2:]\n",
    "    sys.stdout.write(text)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = args.lr * (0.1 ** (epoch // 50))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def get_avg(self):\n",
    "        return self.avg\n",
    "    \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "def compute_accuracy(output, target):\n",
    "    output = output.argmax(dim=1)\n",
    "    acc = 0.0\n",
    "    acc = torch.sum(target == output).item()\n",
    "    acc = acc/output.size(0)*100\n",
    "    return acc\n",
    "    \n",
    "def train(train_loader, model, criterion, optimizer, epoch, args):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "\n",
    "    if args.fedprox: global_model = deepcopy(model)\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    \n",
    "    print('===================================================================')\n",
    "    end = time.time()\n",
    "    \n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        \n",
    "        # # Ensure the target shape is sth like torch.Size([batch_size])\n",
    "        if len(target.shape) > 1: target = target.reshape(len(target))\n",
    "\n",
    "        target.unsqueeze_(1)\n",
    "        target_onehot = torch.FloatTensor(target.shape[0], _NUM_CLASSES)\n",
    "        target_onehot.zero_()\n",
    "        target_onehot.scatter_(1, target, 1)\n",
    "        target.squeeze_(1)\n",
    "        \n",
    "        images = images.to(DEVICE)\n",
    "        target_onehot = target_onehot.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "\n",
    "        output = model(images)\n",
    "        \n",
    "        if args.fedprox:\n",
    "            proximal_term = 0\n",
    "            for local_weights, global_weights in zip(model.parameters(), global_model.parameters()):\n",
    "                proximal_term += (local_weights - global_weights).norm(2)\n",
    "            loss = criterion(output, target_onehot) + (args.mu / 2) * proximal_term\n",
    "        \n",
    "        else:\n",
    "            loss = criterion(output, target_onehot)\n",
    "        \n",
    "        # measure accuracy and record loss\n",
    "        batch_acc = compute_accuracy(output, target)\n",
    "        \n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        acc.update(batch_acc, images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        # Update statistics\n",
    "        estimated_time_remained = batch_time.get_avg()*(len(train_loader)-i-1)\n",
    "        update_progress(i, len(train_loader), \n",
    "            ESA='{:8.2f}'.format(estimated_time_remained)+'s',\n",
    "            loss='{:4.2f}'.format(loss.item()),\n",
    "            acc='{:4.2f}%'.format(float(batch_acc))\n",
    "            )\n",
    "\n",
    "    print()\n",
    "    print('Finish epoch {}: time = {:8.2f}s, loss = {:4.2f}, acc = {:4.2f}%'.format(\n",
    "            epoch+1, batch_time.get_avg()*len(train_loader), \n",
    "            float(losses.get_avg()), float(acc.get_avg())))\n",
    "    print('===================================================================')\n",
    "    return\n",
    "\n",
    "\n",
    "def eval(test_loader, model, args):\n",
    "    batch_time = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "\n",
    "    # switch to eval mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(test_loader):\n",
    "\n",
    "        if len(target.shape) > 1: target = target.reshape(len(target))\n",
    "\n",
    "        images = images.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "        \n",
    "        output = model(images)\n",
    "        batch_acc = compute_accuracy(output, target)\n",
    "        acc.update(batch_acc, images.size(0))\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # Update statistics\n",
    "        estimated_time_remained = batch_time.get_avg()*(len(test_loader)-i-1)\n",
    "        update_progress(i, len(test_loader), \n",
    "            ESA='{:8.2f}'.format(estimated_time_remained)+'s',\n",
    "            acc='{:4.2f}'.format(float(batch_acc))\n",
    "            )\n",
    "    print()\n",
    "    print('Test accuracy: {:4.2f}% (time = {:8.2f}s)'.format(\n",
    "            float(acc.get_avg()), batch_time.get_avg()*len(test_loader)))\n",
    "    print('===================================================================')\n",
    "    return float(acc.get_avg())\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet_reduced(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AlexNet_reduced, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=3, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def alexnet_reduced(reducing_rate=1, pretrained=False, progress=True, num_classes=1000):\n",
    "    r\"\"\"AlexNet model architecture from the\n",
    "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = AlexNet_reduced()\n",
    "    if pretrained:\n",
    "        state_dict = model_zoo.load_url(model_urls['alexnet'], progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    if num_classes != 1000:\n",
    "        num_in_feature = model.classifier[6].in_features\n",
    "        model.classifier[6] = nn.Linear(num_in_feature, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(project_folder='./projects/test/test_other_datasets/', model_name='alexnet.pth.tar', no_clients=56, no_rounds=300, fine_tuning_epochs=50, use_server_data=False, fedprox=False, mu=0.01, client_selection=True, pretrained=False, generate_dataset=False, niid=None, b=None, p=None, alpha=None, dataset_path='./data/32_Cifar10_NIID_56c_a03', epochs=200, arch='alexnet_reduced', workers=4, batch_size=128, lr=0.001, momentum=0.9, weight_decay=0.0005)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_args = {\n",
    "  \"project_folder\": \"./projects/test/test_other_datasets/\",\n",
    "  \"model_name\": \"alexnet.pth.tar\",\n",
    "  \"no_clients\": 56,\n",
    "  \"no_rounds\": 300,\n",
    "  \"fine_tuning_epochs\": 50,\n",
    "  \"use_server_data\": False,\n",
    "  \"fedprox\": False,\n",
    "  \"mu\": 0.01,\n",
    "  \"client_selection\": True,\n",
    "  \"pretrained\": False,\n",
    "  \"generate_dataset\": False,\n",
    "  \"niid\": None,\n",
    "  \"b\": None,\n",
    "  \"p\": None,\n",
    "  \"alpha\": None,\n",
    "  \"dataset_path\": \"./data/32_Cifar10_NIID_56c_a03\",\n",
    "  \"epochs\": 200,\n",
    "  \"arch\": \"alexnet_reduced\",\n",
    "  \"workers\": 4,\n",
    "  \"batch_size\": 128,\n",
    "  \"lr\": 0.001,\n",
    "  \"momentum\": 0.9,\n",
    "  \"weight_decay\": 0.0005\n",
    "}\n",
    "args = Namespace(**pre_args)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "alexmodel = alexnet_reduced(num_classes=100)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    ])\n",
    "\n",
    "train_dataset = datasets.CIFAR100(root=\"../data\", train=True, download=True,\n",
    "        transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=args.batch_size, shuffle=True,\n",
    "    num_workers=args.workers, pin_memory=True)\n",
    "test_dataset = datasets.CIFAR100(root=\"../data\", train=False, download=True,\n",
    "    transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=args.batch_size, shuffle=True,\n",
    "    num_workers=args.workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200]\n",
      "===================================================================\n",
      "Percent: [##########] 99.74% (390/391) ESA:     0.00s, loss: 0.54, acc: 0.00%\n",
      "Finish epoch 1: time =    63.35s, loss = 0.67, acc = 0.93%\n",
      "===================================================================\n",
      "Percent: [##########] 98.73% (78/79) ESA:     0.00s, acc: 0.00\n",
      "Test accuracy: 1.00% (time =     7.48s)\n",
      "===================================================================\n",
      " \n",
      "Epoch [2/200]\n",
      "===================================================================\n",
      "Percent: [##########] 99.74% (390/391) ESA:     0.00s, loss: 0.06, acc: 0.00%\n",
      "Finish epoch 2: time =    62.68s, loss = 0.09, acc = 0.93%\n",
      "===================================================================\n",
      "Percent: [##########] 98.73% (78/79) ESA:     0.00s, acc: 0.00\n",
      "Test accuracy: 0.98% (time =     7.87s)\n",
      "===================================================================\n",
      " \n",
      "Epoch [3/200]\n",
      "===================================================================\n",
      "Percent: [##########] 99.74% (390/391) ESA:     0.00s, loss: 0.06, acc: 2.50%\n",
      "Finish epoch 3: time =    63.49s, loss = 0.06, acc = 1.02%\n",
      "===================================================================\n",
      "Percent: [##########] 98.73% (78/79) ESA:     0.00s, acc: 0.00\n",
      "Test accuracy: 1.04% (time =     7.73s)\n",
      "===================================================================\n",
      " \n",
      "Epoch [4/200]\n",
      "===================================================================\n",
      "Percent: [##########] 99.74% (390/391) ESA:     0.00s, loss: 0.06, acc: 1.25%\n",
      "Finish epoch 4: time =    63.55s, loss = 0.06, acc = 1.05%\n",
      "===================================================================\n",
      "Percent: [##########] 98.73% (78/79) ESA:     0.00s, acc: 0.00\n",
      "Test accuracy: 1.03% (time =     7.99s)\n",
      "===================================================================\n",
      " \n",
      "Epoch [5/200]\n",
      "===================================================================\n",
      "Percent: [######----] 55.75% (218/391) ESA:    29.68s, loss: 0.06, acc: 0.00%"
     ]
    }
   ],
   "source": [
    "# Network\n",
    "cudnn.benchmark = True\n",
    "num_classes = _NUM_CLASSES\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(alexmodel.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay)\n",
    "# model = nn.DataParallel(model)\n",
    "alexmodel = alexmodel.to(DEVICE)\n",
    "criterion = criterion.to(DEVICE)\n",
    "# Train & evaluation\n",
    "best_acc = 0\n",
    "for epoch in range(args.epochs):\n",
    "    print('Epoch [{}/{}]'.format(epoch+1, args.epochs))\n",
    "    adjust_learning_rate(optimizer, epoch, args)\n",
    "    # train for one epoch\n",
    "    train(train_loader, alexmodel, criterion, optimizer, epoch, args)\n",
    "    acc = eval(test_loader, alexmodel, args)\n",
    "    \n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "    print(' ')\n",
    "print('Best accuracy:', best_acc)\n",
    "    \n",
    "best_acc = eval(test_loader, alexmodel, args)\n",
    "print('Best accuracy:', best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
