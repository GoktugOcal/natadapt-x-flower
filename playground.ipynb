{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflowers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcustomDataset\u001b[39;00m \u001b[39mimport\u001b[39;00m CustomDataset\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m data \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(\u001b[39mopen\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39m./data/Cifar10/train/0.pkl\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from flowers.utils.customDataset import CustomDataset\n",
    "\n",
    "data = pickle.load(open(\"./data/Cifar10/train/0.pkl\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader\n",
    "batch_size = 32  # Adjust this as needed\n",
    "dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type: (1, 1, 3), <f4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/python_envs/easyfl/lib/python3.10/site-packages/PIL/Image.py:3070\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3069\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3070\u001b[0m     mode, rawmode \u001b[39m=\u001b[39m _fromarray_typemap[typekey]\n\u001b[1;32m   3071\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyError\u001b[0m: ((1, 1, 3), '<f4')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dataloader\u001b[39m.\u001b[39;49mdataset[\u001b[39m0\u001b[39;49m][\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m~/Desktop/thesis/netadapt-x-flower/utils/customDataset.py:19\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     17\u001b[0m img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[idx]\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39marray(img, dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39muint8)\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 19\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(np\u001b[39m.\u001b[39marray(img, dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39muint8))\u001b[39m.\u001b[39mconvert(\u001b[39m'\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(img)\n",
      "File \u001b[0;32m~/python_envs/easyfl/lib/python3.10/site-packages/PIL/Image.py:3073\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3071\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   3072\u001b[0m         msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCannot handle this data type: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m typekey\n\u001b[0;32m-> 3073\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m   3074\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3075\u001b[0m     rawmode \u001b[39m=\u001b[39m mode\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot handle this data type: (1, 1, 3), <f4"
     ]
    }
   ],
   "source": [
    "dataloader.dataset[0][\"data\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import ConcatDataset, TensorDataset, DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "from flowers.non_iid_generator.utils.dataset_utils import check, separate_data, split_data, save_file\n",
    "\n",
    "from flowers.utils.customDataset import CustomDataset\n",
    "from argparse import ArgumentParser\n",
    "dir_path = \"./data/Cifar10/\"\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data[idx]\n",
    "        np_img = np.array(img, dtype = np.uint8)\n",
    "        # print(type(np_img))\n",
    "        # print(np_img.shape)\n",
    "        img = Image.fromarray(np_img, \"RGB\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            # print(\"-->\", type(img))\n",
    "            # print(type(img))\n",
    "            # print(img.shape)\n",
    "\n",
    "        class_id = torch.tensor([self.labels[idx]])\n",
    "\n",
    "        sample = {\n",
    "            'data': img,\n",
    "            'label': self.labels[idx]\n",
    "        }\n",
    "        \n",
    "        return img, class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# transform = transforms.Compose(\n",
    "#     [\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4), \n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=dir_path+\"rawdata\", train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=dir_path+\"rawdata\", train=False, download=True, transform=transform)\n",
    "\n",
    "# ttset = ConcatDataset([trainset, trainset])\n",
    "\n",
    "# ttloader = torch.utils.data.DataLoader(ttset, batch_size=len(trainset.data), shuffle=False)\n",
    "\n",
    "# trainloader = torch.utils.data.DataLoader(\n",
    "#     trainset, batch_size=len(trainset.data), shuffle=False)\n",
    "# testloader = torch.utils.data.DataLoader(\n",
    "#     testset, batch_size=len(testset.data), shuffle=False)\n",
    "\n",
    "dataset_image = []\n",
    "dataset_image.extend(trainset.data)\n",
    "dataset_image.extend(testset.data)\n",
    "dataset_image = np.array(dataset_image)\n",
    "\n",
    "train_targets = trainset.targets\n",
    "test_targets = testset.targets\n",
    "\n",
    "dataset_label = []\n",
    "dataset_label.extend(train_targets)\n",
    "dataset_label.extend(test_targets)\n",
    "dataset_label = np.array(dataset_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "batch_size = 32\n",
    "def save_file(config_path, train_path, test_path, train_data, test_data, num_clients, \n",
    "                num_classes, statistic, niid=False, balance=True, partition=None):\n",
    "    config = {\n",
    "        'num_clients': num_clients, \n",
    "        'num_classes': num_classes, \n",
    "        'non_iid': niid, \n",
    "        'balance': balance, \n",
    "        'partition': partition, \n",
    "        'Size of samples for labels in clients': statistic, \n",
    "        'alpha': alpha, \n",
    "        'batch_size': batch_size, \n",
    "    }\n",
    "\n",
    "    # gc.collect()\n",
    "    print(\"Saving to disk.\\n\")\n",
    "\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4), \n",
    "        transforms.Resize(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    ])\n",
    "\n",
    "    for idx, train_dict in enumerate(train_data):\n",
    "        data = train_dict[\"x\"]\n",
    "        labels = train_dict[\"y\"]\n",
    "        # tensor_x = torch.Tensor(data) # transform to torch tensor\n",
    "        # tensor_y = torch.Tensor(labels)\n",
    "\n",
    "        # my_dataset = TensorDataset(tensor_x,tensor_y) # create your datset\n",
    "        # my_dataloader = DataLoader(my_dataset) # create your dataloader\n",
    "\n",
    "\n",
    "        # for idx, train_data in enumerate(my_dataloader, 0):\n",
    "        #     data, labels = train_data\n",
    "        #     print(data)\n",
    "\n",
    "\n",
    "        \n",
    "        data = train_dict[\"x\"]\n",
    "        labels = train_dict[\"y\"]\n",
    "        custom_dataset = CustomDataset(data, labels, transform=transform)\n",
    "        print(custom_dataset[0])\n",
    "\n",
    "        with open(train_path + str(idx) + '.pkl', 'wb') as f:\n",
    "            pickle.dump(custom_dataset, f)\n",
    "\n",
    "    # for idx, test_dict in enumerate(test_data):\n",
    "    #     with open(test_path + str(idx) + '.npz', 'wb') as f:\n",
    "    #         np.savez_compressed(f, data=test_dict)\n",
    "    # with open(config_path, 'w') as f:\n",
    "    #     ujson.dump(config, f)\n",
    "\n",
    "    # print(\"Finish generating dataset.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0\t Size of data: 23214\t Labels:  [0 3 4 6 7 8]\n",
      "\t\t Samples of labels:  [(0, 5240), (3, 1303), (4, 5994), (6, 4934), (7, 321), (8, 5422)]\n",
      "--------------------------------------------------\n",
      "Client 1\t Size of data: 16854\t Labels:  [0 1 2 3 4 5 6 7 9]\n",
      "\t\t Samples of labels:  [(0, 31), (1, 258), (2, 5999), (3, 1009), (4, 5), (5, 5999), (6, 1060), (7, 387), (9, 2106)]\n",
      "--------------------------------------------------\n",
      "Client 2\t Size of data: 19932\t Labels:  [0 1 2 3 4 5 6 7 8 9]\n",
      "\t\t Samples of labels:  [(0, 729), (1, 5742), (2, 1), (3, 3688), (4, 1), (5, 1), (6, 6), (7, 5292), (8, 578), (9, 3894)]\n",
      "--------------------------------------------------\n",
      "Total number of samples: 60000\n",
      "The number of train samples: [17410, 12640, 14949]\n",
      "The number of test samples: [5804, 4214, 4983]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_clients = 3\n",
    "num_classes = 10\n",
    "niid = True\n",
    "balance = False\n",
    "partition = \"dir\"\n",
    "\n",
    "X, y, statistic = separate_data((dataset_image, dataset_label), num_clients, num_classes, \n",
    "                                niid, balance, partition)\n",
    "\n",
    "train_data, test_data = split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to disk.\n",
      "\n",
      "(tensor([[[-0.8201, -0.8201, -0.8201,  ..., -2.4291, -2.4291, -2.4291],\n",
      "         [-0.8201, -0.8201, -0.8201,  ..., -2.4291, -2.4291, -2.4291],\n",
      "         [-0.8201, -0.8201, -0.8201,  ..., -2.4291, -2.4291, -2.4291],\n",
      "         ...,\n",
      "         [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "         [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "         [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291]],\n",
      "\n",
      "        [[-0.3532, -0.3532, -0.3532,  ..., -2.4183, -2.4183, -2.4183],\n",
      "         [-0.3532, -0.3532, -0.3532,  ..., -2.4183, -2.4183, -2.4183],\n",
      "         [-0.3532, -0.3532, -0.3532,  ..., -2.4183, -2.4183, -2.4183],\n",
      "         ...,\n",
      "         [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "         [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "         [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183]],\n",
      "\n",
      "        [[-1.1483, -1.1483, -1.1483,  ..., -2.2214, -2.2214, -2.2214],\n",
      "         [-1.1483, -1.1483, -1.1483,  ..., -2.2214, -2.2214, -2.2214],\n",
      "         [-1.1483, -1.1483, -1.1483,  ..., -2.2214, -2.2214, -2.2214],\n",
      "         ...,\n",
      "         [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "         [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "         [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214]]]), tensor([7]))\n",
      "(tensor([[[-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "         [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "         [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "         ...,\n",
      "         [-2.4291, -2.4291, -2.4291,  ...,  0.4593,  0.4593,  0.4593],\n",
      "         [-2.4291, -2.4291, -2.4291,  ...,  0.4593,  0.4593,  0.4593],\n",
      "         [-2.4291, -2.4291, -2.4291,  ...,  0.4593,  0.4593,  0.4593]],\n",
      "\n",
      "        [[-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "         [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "         [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "         ...,\n",
      "         [-2.4183, -2.4183, -2.4183,  ...,  1.0431,  1.0431,  1.0431],\n",
      "         [-2.4183, -2.4183, -2.4183,  ...,  1.0431,  1.0431,  1.0431],\n",
      "         [-2.4183, -2.4183, -2.4183,  ...,  1.0431,  1.0431,  1.0431]],\n",
      "\n",
      "        [[-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "         [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "         [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "         ...,\n",
      "         [-2.2214, -2.2214, -2.2214,  ..., -1.3434, -1.3434, -1.3434],\n",
      "         [-2.2214, -2.2214, -2.2214,  ..., -1.3434, -1.3434, -1.3434],\n",
      "         [-2.2214, -2.2214, -2.2214,  ..., -1.3434, -1.3434, -1.3434]]]), tensor([6]))\n",
      "(tensor([[[-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "         [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "         [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "         ...,\n",
      "         [-2.4291, -2.4291, -2.4291,  ...,  0.1491,  0.1491,  0.1491],\n",
      "         [-2.4291, -2.4291, -2.4291,  ...,  0.1491,  0.1491,  0.1491],\n",
      "         [-2.4291, -2.4291, -2.4291,  ...,  0.1491,  0.1491,  0.1491]],\n",
      "\n",
      "        [[-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "         [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "         [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "         ...,\n",
      "         [-2.4183, -2.4183, -2.4183,  ...,  0.0401,  0.0401,  0.0401],\n",
      "         [-2.4183, -2.4183, -2.4183,  ...,  0.0401,  0.0401,  0.0401],\n",
      "         [-2.4183, -2.4183, -2.4183,  ...,  0.0401,  0.0401,  0.0401]],\n",
      "\n",
      "        [[-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "         [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "         [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "         ...,\n",
      "         [-2.2214, -2.2214, -2.2214,  ...,  0.0223,  0.0223,  0.0223],\n",
      "         [-2.2214, -2.2214, -2.2214,  ...,  0.0223,  0.0223,  0.0223],\n",
      "         [-2.2214, -2.2214, -2.2214,  ...,  0.0223,  0.0223,  0.0223]]]), tensor([1]))\n"
     ]
    }
   ],
   "source": [
    "config_path = dir_path + \"config.json\"\n",
    "train_path = dir_path + \"train/\"\n",
    "test_path = dir_path + \"test/\"\n",
    "\n",
    "save_file(config_path, train_path, test_path, train_data, test_data, num_clients, num_classes, \n",
    "        statistic, niid, balance, partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(\u001b[39mopen\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39m./data/Cifar10/train/0.pkl\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m  \u001b[39m# Adjust this as needed\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m dataloader \u001b[39m=\u001b[39m DataLoader(data, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "data = pickle.load(open(\"./data/Cifar10/train/0.pkl\", \"rb\"))\n",
    "batch_size = 32  # Adjust this as needed\n",
    "dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17410"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "ACC: 0.0017805858701895462\n",
      "63\n",
      "ACC: 0.0036186099942561744\n",
      "95\n",
      "ACC: 0.005456634118322803\n",
      "127\n",
      "ACC: 0.007294658242389431\n",
      "159\n",
      "ACC: 0.00913268236645606\n",
      "189\n",
      "ACC: 0.010855829982768524\n",
      "220\n",
      "ACC: 0.01263641585295807\n",
      "252\n",
      "ACC: 0.014474439977024698\n",
      "284\n",
      "ACC: 0.01631246410109133\n",
      "315\n",
      "ACC: 0.01809304997128087\n",
      "347\n",
      "ACC: 0.0199310740953475\n",
      "379\n",
      "ACC: 0.02176909821941413\n",
      "410\n",
      "ACC: 0.023549684089603676\n",
      "442\n",
      "ACC: 0.025387708213670306\n",
      "474\n",
      "ACC: 0.02722573233773693\n",
      "505\n",
      "ACC: 0.029006318207926478\n",
      "537\n",
      "ACC: 0.030844342331993107\n",
      "569\n",
      "ACC: 0.032682366456059736\n",
      "600\n",
      "ACC: 0.03446295232624928\n",
      "630\n",
      "ACC: 0.03618609994256174\n",
      "662\n",
      "ACC: 0.038024124066628376\n",
      "694\n",
      "ACC: 0.039862148190695\n",
      "726\n",
      "ACC: 0.041700172314761634\n",
      "758\n",
      "ACC: 0.04353819643882826\n",
      "788\n",
      "ACC: 0.04526134405514072\n",
      "819\n",
      "ACC: 0.04704192992533027\n",
      "850\n",
      "ACC: 0.048822515795519814\n",
      "882\n",
      "ACC: 0.050660539919586446\n",
      "914\n",
      "ACC: 0.05249856404365307\n",
      "946\n",
      "ACC: 0.054336588167719704\n",
      "978\n",
      "ACC: 0.05617461229178633\n",
      "1009\n",
      "ACC: 0.05795519816197588\n",
      "1041\n",
      "ACC: 0.0597932222860425\n",
      "1072\n",
      "ACC: 0.06157380815623205\n",
      "1104\n",
      "ACC: 0.06341183228029867\n",
      "1135\n",
      "ACC: 0.06519241815048822\n",
      "1166\n",
      "ACC: 0.06697300402067777\n",
      "1198\n",
      "ACC: 0.0688110281447444\n",
      "1230\n",
      "ACC: 0.07064905226881103\n",
      "1262\n",
      "ACC: 0.07248707639287766\n",
      "1294\n",
      "ACC: 0.07432510051694428\n",
      "1326\n",
      "ACC: 0.07616312464101091\n",
      "1357\n",
      "ACC: 0.07794371051120046\n",
      "1386\n",
      "ACC: 0.07960941987363584\n",
      "1418\n",
      "ACC: 0.08144744399770247\n",
      "1450\n",
      "ACC: 0.0832854681217691\n",
      "1482\n",
      "ACC: 0.08512349224583572\n",
      "1513\n",
      "ACC: 0.08690407811602527\n",
      "1545\n",
      "ACC: 0.08874210224009191\n",
      "1574\n",
      "ACC: 0.09040781160252728\n",
      "1603\n",
      "ACC: 0.09207352096496267\n",
      "1634\n",
      "ACC: 0.09385410683515222\n",
      "1665\n",
      "ACC: 0.09563469270534176\n",
      "1695\n",
      "ACC: 0.09735784032165422\n",
      "1727\n",
      "ACC: 0.09919586444572084\n",
      "1759\n",
      "ACC: 0.10103388856978748\n",
      "1791\n",
      "ACC: 0.10287191269385411\n",
      "1823\n",
      "ACC: 0.10470993681792073\n",
      "1853\n",
      "ACC: 0.1064330844342332\n",
      "1884\n",
      "ACC: 0.10821367030442275\n",
      "1915\n",
      "ACC: 0.1099942561746123\n",
      "1947\n",
      "ACC: 0.11183228029867892\n",
      "1978\n",
      "ACC: 0.11361286616886847\n",
      "2009\n",
      "ACC: 0.11539345203905801\n",
      "2041\n",
      "ACC: 0.11723147616312464\n",
      "2073\n",
      "ACC: 0.11906950028719127\n",
      "2105\n",
      "ACC: 0.12090752441125789\n",
      "2135\n",
      "ACC: 0.12263067202757036\n",
      "2167\n",
      "ACC: 0.12446869615163698\n",
      "2199\n",
      "ACC: 0.1263067202757036\n",
      "2231\n",
      "ACC: 0.12814474439977025\n",
      "2262\n",
      "ACC: 0.12992533026995978\n",
      "2294\n",
      "ACC: 0.13176335439402642\n",
      "2326\n",
      "ACC: 0.13360137851809306\n",
      "2358\n",
      "ACC: 0.13543940264215967\n",
      "2390\n",
      "ACC: 0.1372774267662263\n",
      "2422\n",
      "ACC: 0.13911545089029292\n",
      "2454\n",
      "ACC: 0.14095347501435956\n",
      "2486\n",
      "ACC: 0.1427914991384262\n",
      "2517\n",
      "ACC: 0.14457208500861574\n",
      "2549\n",
      "ACC: 0.14641010913268238\n",
      "2581\n",
      "ACC: 0.148248133256749\n",
      "2612\n",
      "ACC: 0.15002871912693855\n",
      "2643\n",
      "ACC: 0.15180930499712808\n",
      "2675\n",
      "ACC: 0.15364732912119472\n",
      "2707\n",
      "ACC: 0.15548535324526133\n",
      "2739\n",
      "ACC: 0.15732337736932797\n",
      "2770\n",
      "ACC: 0.15910396323951753\n",
      "2802\n",
      "ACC: 0.16094198736358414\n",
      "2834\n",
      "ACC: 0.16278001148765078\n",
      "2865\n",
      "ACC: 0.16456059735784032\n",
      "2897\n",
      "ACC: 0.16639862148190696\n",
      "2928\n",
      "ACC: 0.1681792073520965\n",
      "2960\n",
      "ACC: 0.17001723147616313\n",
      "2991\n",
      "ACC: 0.17179781734635266\n",
      "3022\n",
      "ACC: 0.17357840321654222\n",
      "3053\n",
      "ACC: 0.17535898908673175\n",
      "3085\n",
      "ACC: 0.1771970132107984\n",
      "3117\n",
      "ACC: 0.17903503733486503\n",
      "3148\n",
      "ACC: 0.18081562320505457\n",
      "3180\n",
      "ACC: 0.1826536473291212\n",
      "3211\n",
      "ACC: 0.18443423319931074\n",
      "3242\n",
      "ACC: 0.1862148190695003\n",
      "3273\n",
      "ACC: 0.18799540493968983\n",
      "3305\n",
      "ACC: 0.18983342906375647\n",
      "3335\n",
      "ACC: 0.19155657668006892\n",
      "3367\n",
      "ACC: 0.19339460080413556\n",
      "3399\n",
      "ACC: 0.19523262492820218\n",
      "3430\n",
      "ACC: 0.19701321079839174\n",
      "3460\n",
      "ACC: 0.1987363584147042\n",
      "3492\n",
      "ACC: 0.20057438253877083\n",
      "3524\n",
      "ACC: 0.20241240666283744\n",
      "3556\n",
      "ACC: 0.20425043078690408\n",
      "3588\n",
      "ACC: 0.20608845491097072\n",
      "3619\n",
      "ACC: 0.20786904078116025\n",
      "3649\n",
      "ACC: 0.2095921883974727\n",
      "3681\n",
      "ACC: 0.21143021252153935\n",
      "3712\n",
      "ACC: 0.21321079839172888\n",
      "3743\n",
      "ACC: 0.21499138426191844\n",
      "3775\n",
      "ACC: 0.21682940838598508\n",
      "3807\n",
      "ACC: 0.2186674325100517\n",
      "3839\n",
      "ACC: 0.22050545663411833\n",
      "3870\n",
      "ACC: 0.22228604250430786\n",
      "3900\n",
      "ACC: 0.22400919012062034\n",
      "3930\n",
      "ACC: 0.2257323377369328\n",
      "3961\n",
      "ACC: 0.22751292360712233\n",
      "3991\n",
      "ACC: 0.2292360712234348\n",
      "4023\n",
      "ACC: 0.23107409534750142\n",
      "4055\n",
      "ACC: 0.23291211947156806\n",
      "4087\n",
      "ACC: 0.2347501435956347\n",
      "4116\n",
      "ACC: 0.23641585295807008\n",
      "4148\n",
      "ACC: 0.23825387708213672\n",
      "4179\n",
      "ACC: 0.24003446295232625\n",
      "4209\n",
      "ACC: 0.2417576105686387\n",
      "4240\n",
      "ACC: 0.24353819643882826\n",
      "4271\n",
      "ACC: 0.2453187823090178\n",
      "4303\n",
      "ACC: 0.24715680643308444\n",
      "4334\n",
      "ACC: 0.24893739230327397\n",
      "4366\n",
      "ACC: 0.25077541642734064\n",
      "4398\n",
      "ACC: 0.2526134405514072\n",
      "4429\n",
      "ACC: 0.2543940264215968\n",
      "4461\n",
      "ACC: 0.2562320505456634\n",
      "4493\n",
      "ACC: 0.25807007466973003\n",
      "4525\n",
      "ACC: 0.25990809879379667\n",
      "4557\n",
      "ACC: 0.2617461229178633\n",
      "4589\n",
      "ACC: 0.26358414704192995\n",
      "4621\n",
      "ACC: 0.26542217116599653\n",
      "4653\n",
      "ACC: 0.2672601952900632\n",
      "4685\n",
      "ACC: 0.2690982194141298\n",
      "4717\n",
      "ACC: 0.27093624353819645\n",
      "4749\n",
      "ACC: 0.2727742676622631\n",
      "4781\n",
      "ACC: 0.2746122917863297\n",
      "4813\n",
      "ACC: 0.2764503159103963\n",
      "4843\n",
      "ACC: 0.2781734635267088\n",
      "4874\n",
      "ACC: 0.27995404939689833\n",
      "4903\n",
      "ACC: 0.2816197587593337\n",
      "4935\n",
      "ACC: 0.28345778288340034\n",
      "4967\n",
      "ACC: 0.285295807007467\n",
      "4998\n",
      "ACC: 0.2870763928776565\n",
      "5030\n",
      "ACC: 0.28891441700172316\n",
      "5061\n",
      "ACC: 0.2906950028719127\n",
      "5093\n",
      "ACC: 0.29253302699597933\n",
      "5125\n",
      "ACC: 0.29437105112004597\n",
      "5157\n",
      "ACC: 0.29620907524411255\n",
      "5188\n",
      "ACC: 0.29798966111430214\n",
      "5217\n",
      "ACC: 0.2996553704767375\n",
      "5249\n",
      "ACC: 0.30149339460080415\n",
      "5281\n",
      "ACC: 0.30333141872487074\n",
      "5312\n",
      "ACC: 0.3051120045950603\n",
      "5344\n",
      "ACC: 0.30695002871912697\n",
      "5375\n",
      "ACC: 0.3087306145893165\n",
      "5407\n",
      "ACC: 0.31056863871338314\n",
      "5437\n",
      "ACC: 0.31229178632969556\n",
      "5469\n",
      "ACC: 0.3141298104537622\n",
      "5499\n",
      "ACC: 0.3158529580700747\n",
      "5531\n",
      "ACC: 0.3176909821941413\n",
      "5562\n",
      "ACC: 0.31947156806433086\n",
      "5594\n",
      "ACC: 0.3213095921883975\n",
      "5626\n",
      "ACC: 0.3231476163124641\n",
      "5657\n",
      "ACC: 0.32492820218265367\n",
      "5688\n",
      "ACC: 0.3267087880528432\n",
      "5719\n",
      "ACC: 0.32848937392303273\n",
      "5751\n",
      "ACC: 0.3303273980470994\n",
      "5783\n",
      "ACC: 0.332165422171166\n",
      "5814\n",
      "ACC: 0.33394600804135555\n",
      "5844\n",
      "ACC: 0.33566915565766803\n",
      "5876\n",
      "ACC: 0.3375071797817346\n",
      "5907\n",
      "ACC: 0.3392877656519242\n",
      "5939\n",
      "ACC: 0.3411257897759908\n",
      "5970\n",
      "ACC: 0.3429063756461804\n",
      "6002\n",
      "ACC: 0.344744399770247\n",
      "6034\n",
      "ACC: 0.3465824238943136\n",
      "6064\n",
      "ACC: 0.3483055715106261\n",
      "6096\n",
      "ACC: 0.3501435956346927\n",
      "6128\n",
      "ACC: 0.35198161975875936\n",
      "6160\n",
      "ACC: 0.35381964388282594\n",
      "6190\n",
      "ACC: 0.3555427914991384\n",
      "6219\n",
      "ACC: 0.3572085008615738\n",
      "6251\n",
      "ACC: 0.35904652498564044\n",
      "6283\n",
      "ACC: 0.3608845491097071\n",
      "6314\n",
      "ACC: 0.3626651349798966\n",
      "6344\n",
      "ACC: 0.3643882825962091\n",
      "6375\n",
      "ACC: 0.3661688684663986\n",
      "6406\n",
      "ACC: 0.36794945433658816\n",
      "6438\n",
      "ACC: 0.3697874784606548\n",
      "6470\n",
      "ACC: 0.37162550258472143\n",
      "6502\n",
      "ACC: 0.3734635267087881\n",
      "6534\n",
      "ACC: 0.37530155083285466\n",
      "6563\n",
      "ACC: 0.3769672601952901\n",
      "6595\n",
      "ACC: 0.37880528431935667\n",
      "6627\n",
      "ACC: 0.3806433084434233\n",
      "6658\n",
      "ACC: 0.38242389431361284\n",
      "6688\n",
      "ACC: 0.3841470419299253\n",
      "6720\n",
      "ACC: 0.38598506605399197\n",
      "6752\n",
      "ACC: 0.3878230901780586\n",
      "6782\n",
      "ACC: 0.38954623779437103\n",
      "6814\n",
      "ACC: 0.39138426191843767\n",
      "6846\n",
      "ACC: 0.3932222860425043\n",
      "6877\n",
      "ACC: 0.39500287191269384\n",
      "6908\n",
      "ACC: 0.3967834577828834\n",
      "6939\n",
      "ACC: 0.39856404365307296\n",
      "6968\n",
      "ACC: 0.40022975301550834\n",
      "7000\n",
      "ACC: 0.402067777139575\n",
      "7030\n",
      "ACC: 0.4037909247558874\n",
      "7061\n",
      "ACC: 0.405571510626077\n",
      "7092\n",
      "ACC: 0.4073520964962665\n",
      "7121\n",
      "ACC: 0.4090178058587019\n",
      "7153\n",
      "ACC: 0.41085582998276854\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb Cell 13\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m correct, loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0.0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m images, labels \u001b[39min\u001b[39;00m dataloader:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39m# labels.unsqueeze_(1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         target_onehot \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor(labels\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m10\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         target_onehot\u001b[39m.\u001b[39mzero_()\n",
      "File \u001b[0;32m~/python_envs/easyfl/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/python_envs/easyfl/lib/python3.10/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/python_envs/easyfl/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/python_envs/easyfl/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32m/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb#X14sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(np_img, \u001b[39m\"\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb#X14sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb#X14sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb#X14sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39m# print(\"-->\", type(img))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb#X14sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39m# print(type(img))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb#X14sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39m# print(img.shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/goktug/Desktop/thesis/netadapt-x-flower/playground.ipynb#X14sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m class_id \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels[idx]])\n",
      "File \u001b[0;32m~/python_envs/easyfl/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/python_envs/easyfl/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/python_envs/easyfl/lib/python3.10/site-packages/torchvision/transforms/transforms.py:361\u001b[0m, in \u001b[0;36mResize.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m    354\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39m        img (PIL Image or Tensor): Image to be scaled.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[39m        PIL Image or Tensor: Rescaled image.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mresize(img, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msize, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterpolation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mantialias)\n",
      "File \u001b[0;32m~/python_envs/easyfl/lib/python3.10/site-packages/torchvision/transforms/functional.py:490\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    488\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    489\u001b[0m     pil_interpolation \u001b[39m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[0;32m--> 490\u001b[0m     \u001b[39mreturn\u001b[39;00m F_pil\u001b[39m.\u001b[39;49mresize(img, size\u001b[39m=\u001b[39;49moutput_size, interpolation\u001b[39m=\u001b[39;49mpil_interpolation)\n\u001b[1;32m    492\u001b[0m \u001b[39mreturn\u001b[39;00m F_t\u001b[39m.\u001b[39mresize(img, size\u001b[39m=\u001b[39moutput_size, interpolation\u001b[39m=\u001b[39minterpolation\u001b[39m.\u001b[39mvalue, antialias\u001b[39m=\u001b[39mantialias)\n",
      "File \u001b[0;32m~/python_envs/easyfl/lib/python3.10/site-packages/torchvision/transforms/_functional_pil.py:250\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(size, \u001b[39mlist\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(size) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m):\n\u001b[1;32m    248\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot inappropriate size arg: \u001b[39m\u001b[39m{\u001b[39;00msize\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 250\u001b[0m \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39;49mresize(\u001b[39mtuple\u001b[39;49m(size[::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]), interpolation)\n",
      "File \u001b[0;32m~/python_envs/easyfl/lib/python3.10/site-packages/PIL/Image.py:2174\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2166\u001b[0m             \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mreduce(\u001b[39mself\u001b[39m, factor, box\u001b[39m=\u001b[39mreduce_box)\n\u001b[1;32m   2167\u001b[0m         box \u001b[39m=\u001b[39m (\n\u001b[1;32m   2168\u001b[0m             (box[\u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m reduce_box[\u001b[39m0\u001b[39m]) \u001b[39m/\u001b[39m factor_x,\n\u001b[1;32m   2169\u001b[0m             (box[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m reduce_box[\u001b[39m1\u001b[39m]) \u001b[39m/\u001b[39m factor_y,\n\u001b[1;32m   2170\u001b[0m             (box[\u001b[39m2\u001b[39m] \u001b[39m-\u001b[39m reduce_box[\u001b[39m0\u001b[39m]) \u001b[39m/\u001b[39m factor_x,\n\u001b[1;32m   2171\u001b[0m             (box[\u001b[39m3\u001b[39m] \u001b[39m-\u001b[39m reduce_box[\u001b[39m1\u001b[39m]) \u001b[39m/\u001b[39m factor_y,\n\u001b[1;32m   2172\u001b[0m         )\n\u001b[0;32m-> 2174\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mim\u001b[39m.\u001b[39;49mresize(size, resample, box))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = torch.load(\"models/alexnet/model_pt21.pth.tar\")\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "correct, loss = 0, 0.0\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader:\n",
    "        \n",
    "        # labels.unsqueeze_(1)\n",
    "        target_onehot = torch.FloatTensor(labels.shape[0], 10)\n",
    "        target_onehot.zero_()\n",
    "        target_onehot.scatter_(1, labels, 1)\n",
    "        # labels.squeeze_(1)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        outputs = net(images.to(DEVICE))\n",
    "        labels_one_hot = target_onehot.to(DEVICE)\n",
    "\n",
    "        loss += criterion(outputs, labels_one_hot).item()\n",
    "        correct += (torch.max(outputs.data, 1)[1] == labels.squeeze_(1)).sum().item()\n",
    "        # print(torch.max(outputs.data, 1)[1].shape)\n",
    "        # print(labels.squeeze(1).shape)\n",
    "        # print((torch.max(outputs.data, 1)[1] == labels.squeeze(1)).shape)\n",
    "        print(correct)\n",
    "        print(f\"ACC: {correct / len(dataloader.dataset)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easyfl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
